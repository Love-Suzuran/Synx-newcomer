##  招新题目中遇到的问题及其解决方案：

#####  说在前面：

在开始做synx题目之前，个人在高中已经接触过信息竞赛，代码理解和实现能力会相对较强（大体上盲打没问题，但是细节很容易出错），且大概三周前已经完成了择栖工作室的ml一轮招新题目，~~为了水字数表示我在认真学~~接下来的困难和解决方案部分包含了参与择栖工作室招新的困难和就解决方案。

###  环境配置问题：

这一点确实困扰我很久，因为最开始自然而然去了博客园去找anoconda的资源。找是找到了，但是版本低到要命（当时我还没发现），于是在建立虚拟环境并且安装相应软件时（如torch）总是下载不了。

接着我就开始问deepseek，试了很久没办法。又去问我们班导生（应该是Synx的副主席谭博铭），他一会又说没有翻墙原因（给我推荐魔戒翻墙），一会说要在cmd里面跑而不是prompt里面跑，一会又说换个源（清华源）

当然，毫无用处

正当我要放弃的时候，我发现了版本过低的问题。

最后也是跑到官网去了……解决掉。





当然不止如此，可以详见第四大题中第一小题。



###  python学习相关：

本人学了信息竞赛，很多python都是类比c++进行理解的（在我的提交中可以很明显看出来）。

主要就是，python他的库函数很多，也有很多简化和变化的地方。

例如我学import torch 和 import numpy as np用相应函数总是理解不到位，有时候也背不下来（不过我相信时间能改变这点）

那怎么解决？deepseek让他逐行翻译代码，看懂了再回来自己按自己的习惯写。

CV编程也尝试过，但是这肯定不行。于是我在纸上盲写了几遍，现在也是基本熟练了。



###  ml学习相关：

其实ml里面的理论部分还好理解，但是到程序实现就很难了。

最开始尝试自己手打，发现困难，于是求助deepseek

ai给我的代码大多数用了torch的函数，最开始也很难受，理解不了。

后面开始把torch的函数改成自己手写，就理解了。



接着是把随机化、mini_batch运用到梯度下降里面。

这些我是在招新里面没见过的，但是我学过贪心算法，并且学过用随机化（模拟退火）解决局部最佳问题，所以概念理解还是没问题。

但是，还是代码实现有问题，因为很多东西都可以很简单的写出来。

最开始我做mini_batch时，用的随机化指针初始位置，然后讨论了很多很多，觉得很麻烦。

后来问了deepseek，发现可以直接将数据打乱随机，只需要一句话就可以满足（浪费1h有点小崩溃）

包括后面我写最后一大题的代码实现时还是很不会做，只能求助deepseek。现在停留在看得懂，背不到的情境中。

